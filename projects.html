<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects | Agraj Katiyar</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <nav class="navbar">
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About</a></li>
                <li><a href="experience.html">Experience</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a href="skills.html">Skills</a></li>
                <li><a href="achievements.html">Achievements</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </nav>
        <div class="content">
            <section id="projects">
                <h2>Projects</h2>
                <h3><a href="https://datasciencejobmarketeda.streamlit.app/" target="_blank">Data Science Job Market EDA</a> (Comprehensive Web Application)</h3>
<p><a href="https://github.com/agraj7/datasciencejobmarketeda/tree/main" target="_blank">GitHub Repository</a></p>
<p><strong>Tools & Technologies Used:</strong> Python, Pandas, BeautifulSoup, Requests, Streamlit, WordCloud, Matplotlib, NLP Techniques</p>
<p><strong>Description:</strong> Data Science Job Market EDA is a comprehensive web application designed to provide an in-depth exploration of the data science job market across various major cities in the United States. This application aggregates real-time job listing data scraped from popular job portals, offering valuable insights for job seekers, recruiters, and analysts. The project was initially started as a personal endeavor to understand market trends and has evolved into a robust tool for exploring job data. Key features include:</p>
<ul>
    <li><strong>Job Data Aggregation:</strong> Scraped over 7,000 job listings across multiple cities (e.g., Philadelphia, New York, San Francisco) using Python's BeautifulSoup and Requests libraries. The data includes details such as job titles, companies, locations, salaries, posting dates, company logos, job links, and company ratings.</li>
    <li><strong>Data Cleaning & Preprocessing:</strong> Applied robust data cleaning techniques using Pandas to handle missing values, convert data types, and ensure consistency across the dataset. Missing salaries and company ratings were imputed using the median, and non-numeric fields were filled with placeholders.</li>
    <li><strong>Natural Language Processing (NLP):</strong> Conducted text analysis on job descriptions to extract key skills and keywords frequently mentioned in job postings. This included generating word clouds to visualize the most common terms and performing sentiment analysis to understand the overall tone of job postings.</li>
    <li><strong>Interactive Dashboard:</strong> Developed an interactive dashboard using Streamlit, allowing users to filter job listings by location, job title, and other criteria. The dashboard displays detailed information about each job listing, including company ratings, logos, and links to the job postings. Summary statistics, such as average salaries and job counts by location, are also provided.</li>
    <li><strong>Visualizations:</strong> Created various visualizations, such as bar charts and word clouds, to display the distribution of job listings across different locations, the frequency of certain keywords in job titles, and the average company ratings and salaries.</li>
</ul>
<p><strong>Challenges & Solutions:</strong></p>
<ul>
    <li><strong>Data Collection:</strong> Scraping a large volume of data across different cities posed challenges related to data consistency and completeness. These were addressed through meticulous data cleaning and preprocessing.</li>
    <li><strong>Scalability:</strong> The initial project was designed for a single city but was later expanded to handle multiple cities by generalizing the scraping and data processing scripts.</li>
    <li><strong>User Interface:</strong> Ensuring that the application was user-friendly and interactive was achieved by leveraging Streamlit’s capabilities, allowing users to easily filter and view data according to their preferences.</li>
</ul>
<p><strong>Conclusion:</strong> This project provided valuable insights into the data science job market and demonstrated the power of combining web scraping, data analysis, and interactive dashboards. The resulting application serves as a powerful tool for understanding market trends and making informed career decisions. Future enhancements could include adding real-time data updates and expanding the analysis to include more cities and job roles.</p>

<p><strong>Deployment:</strong> The project has been deployed as a web application and can be accessed by anyone interested in exploring the data science job market. The code is available on GitHub, and the application can be easily run locally or on a cloud platform.</p>

<p><strong>Live Demo:</strong> <a href="https://datasciencejobmarketeda.streamlit.app/" target="_blank">Live Demo</a></p>

<p>This project not only highlights technical skills in Python, web scraping, and data visualization but also demonstrates the ability to build practical applications that address real-world needs.</p>

                <h3><a href="https://akshoponline-frontend.vercel.app/" target="_blank">ShopOnline</a> (Full Stack Project)</h3>
                <p><a href="https://github.com/agraj7/shopOnline" target="_blank">GitHub Repository</a></p>
                <p><strong>Tools & Technologies Used:</strong> HTML5, CSS3, JavaScript, React, Node.js, Express.js, MongoDB, Stripe, Cloudinary, Material UI</p>
                <p><strong>Description:</strong> ShopOnline is an extensive e-commerce platform built to provide users with a seamless online shopping experience. The project features a user-friendly interface allowing customers to browse through a wide array of products, manage their shopping cart, and securely place orders. Users can also rate and review products, contributing to a dynamic and interactive shopping environment. The admin panel provides comprehensive control over user management, product catalog, and order processing. Key technical aspects include:</p>
                <ul>
                    <li><strong>Secure Transactions:</strong> Integration with Stripe for processing payments ensures secure and reliable financial transactions.</li>
                    <li><strong>Image Management:</strong> Utilizes Cloudinary for managing and optimizing product images, enhancing load times and image quality.</li>
                    <li><strong>Responsive Design:</strong> Built with Material UI to ensure a modern, responsive layout that adapts seamlessly to various devices and screen sizes.</li>
                    <li><strong>Real-Time Updates:</strong> React’s state management facilitates real-time updates across the application, providing a smooth user experience.</li>
                </ul>
                <h3><a href="https://github.com/agraj7/yourAppointments" target="_blank">YourAppointments</a></h3>
                <p>Tools & technologies used: HTML5, CSS3, JavaScript, React, Node.js</p>
                <p>YourAppointments is a React project where users can set, search, edit, update, or delete appointments.</p>
            </section>
        </div>
    </div>
</body>
</html>
